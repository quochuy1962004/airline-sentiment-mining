import os
import re
import warnings
import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.metrics import (
    classification_report, confusion_matrix, accuracy_score
)
from sklearn.decomposition import PCA

warnings.filterwarnings("ignore", category=RuntimeWarning)
pd.set_option("display.max_colwidth", 120)
RANDOM_STATE = 42


def main():
    # ===== 2. Read Data =====
    DATA_PATH = "data/Tweets.csv"

    if DATA_PATH is None:
        raise FileNotFoundError(
            "Kh√¥ng t√¨m th·∫•y file Tweets.csv. H√£y ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n.\n"
            "V√≠ d·ª•: data/Tweets.csv"
        )

    df = pd.read_csv(DATA_PATH)
    print("ƒê√£ ƒë·ªçc d·ªØ li·ªáu:", DATA_PATH)
    print("th√¥ng tin d·ªØ li·ªáu")
    df.info()

    # ===== 3. EDA c∆° b·∫£n =====
    plt.figure(figsize=(6, 4))
    sns.countplot(x="airline_sentiment", data=df, palette="Set2")
    plt.title("Ph√¢n b·ªë c·∫£m x√∫c ng∆∞·ªùi d√πng")
    plt.xlabel("Sentiment")
    plt.ylabel("S·ªë l∆∞·ª£ng")
    plt.show()

    print("S·ªë l∆∞·ª£ng theo sentiment:\n", df["airline_sentiment"].value_counts())

    # ===== 4. L√†m s·∫°ch text =====
    def clean_text(text):
        text = str(text).lower()
        text = re.sub(r"http\S+", " ", text)       # b·ªè URL
        text = re.sub(r"@\w+", " ", text)          # b·ªè mention
        text = re.sub(r"#", " ", text)             # b·ªè d·∫•u #
        text = re.sub(r"[^a-z\s]", " ", text)      # b·ªè k√Ω t·ª± kh√¥ng ph·∫£i ch·ªØ
        text = re.sub(r"\s+", " ", text).strip()   # b·ªè kho·∫£ng tr·∫Øng d∆∞
        return text

    df["text"] = df["text"].fillna("")
    df["clean_text"] = df["text"].apply(clean_text)
    print("\nV√≠ d·ª• text sau khi clean:")
    print(df[["text", "clean_text"]].head())

    # ===== 5. WordCloud cho t·ª´ng sentiment =====
    for sentiment in df["airline_sentiment"].unique():
        text_blob = " ".join(df.loc[df["airline_sentiment"] == sentiment, "clean_text"])
        if len(text_blob) < 10:  # tr√°nh l·ªói v·ªõi nh√≥m qu√° √≠t
            continue
        plt.figure(figsize=(7, 4))
        wc = WordCloud(width=900, height=400, background_color="white").generate(text_blob)
        plt.imshow(wc, interpolation="bilinear")
        plt.axis("off")
        plt.title(f"WordCloud ‚Äì {sentiment}")
        plt.show()

    # ===== 6. Ph√¢n t√≠ch m·ªü r·ªông =====
    # 6.1 Sentiment theo airline
    plt.figure(figsize=(10, 6))
    sentiment_by_airline = df.groupby(["airline", "airline_sentiment"]).size().unstack(fill_value=0)
    sentiment_by_airline.plot(
        kind="bar", stacked=True, figsize=(10, 6), colormap="coolwarm"
    )
    plt.title("T·ª∑ l·ªá sentiment theo h√£ng h√†ng kh√¥ng")
    plt.ylabel("S·ªë l∆∞·ª£ng tweet")
    plt.xlabel("H√£ng h√†ng kh√¥ng")
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()

    # 6.2 Sentiment theo gi·ªù
    if "tweet_created" in df.columns:
        df["tweet_created"] = pd.to_datetime(df["tweet_created"], errors="coerce")
        df["hour"] = df["tweet_created"].dt.hour
        plt.figure(figsize=(12, 5))
        sns.countplot(
            data=df,
            x="hour",
            hue="airline_sentiment",
            palette="Set2",
            order=sorted(df["hour"].dropna().unique()),
        )
        plt.title("C·∫£m x√∫c theo gi·ªù ƒëƒÉng tweet")
        plt.xlabel("Gi·ªù (0‚Äì23)")
        plt.ylabel("S·ªë l∆∞·ª£ng tweet")
        plt.legend(title="Sentiment")
        plt.tight_layout()
        plt.show()

    # 6.3 Top m√∫i gi·ªù
    if "user_timezone" in df.columns:
        top_tz = df["user_timezone"].value_counts().head(10)
        if len(top_tz) > 0:
            plt.figure(figsize=(9, 4))
            sns.barplot(x=top_tz.values, y=top_tz.index, palette="viridis")
            plt.title("Top 10 m√∫i gi·ªù c·ªßa ng∆∞·ªùi d√πng")
            plt.xlabel("S·ªë l∆∞·ª£ng")
            plt.ylabel("M√∫i gi·ªù")
            plt.tight_layout()
            plt.show()

    # 6.4 L√Ω do ti√™u c·ª±c
    if "negativereason" in df.columns:
        neg_reason = df["negativereason"].value_counts().head(12)
        if len(neg_reason) > 0:
            plt.figure(figsize=(9, 5))
            sns.barplot(y=neg_reason.index, x=neg_reason.values, palette="Reds_r")
            plt.title("Top l√Ω do ng∆∞·ªùi d√πng ph√†n n√†n (negative)")
            plt.xlabel("S·ªë l∆∞·ª£ng tweet")
            plt.ylabel("L√Ω do")
            plt.tight_layout()
            plt.show()

    # 6.5 ƒê·ªô d√†i tweet theo sentiment
    df["text_length"] = df["clean_text"].apply(lambda s: len(s.split()))
    plt.figure(figsize=(7, 5))
    sns.boxplot(x="airline_sentiment", y="text_length", data=df, palette="Set2")
    plt.title("Ph√¢n b·ªë ƒë·ªô d√†i tweet theo c·∫£m x√∫c")
    plt.xlabel("Sentiment")
    plt.ylabel("S·ªë t·ª´")
    plt.tight_layout()
    plt.show()

    # ===== 7. TF-IDF + Train/Test Split =====
    X_text = df["clean_text"]
    y = df["airline_sentiment"]

    tfidf = TfidfVectorizer(max_features=5000, stop_words="english")
    X_tfidf = tfidf.fit_transform(X_text)

    X_train, X_test, y_train, y_test = train_test_split(
        X_tfidf, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y
    )

    # ===== 8. Train & So s√°nh nhi·ªÅu model =====
    models = {
        "Naive Bayes": MultinomialNB(),
        "Logistic Regression": LogisticRegression(max_iter=1000, n_jobs=None),
        "Linear SVM": LinearSVC(),
    }

    results = []
    for name, clf in models.items():
        clf.fit(X_train, y_train)
        pred = clf.predict(X_test)
        acc = round(accuracy_score(y_test, pred), 4)
        results.append((name, acc))
        print(f"\n================= {name} =================")
        print("Accuracy:", acc)
        print(classification_report(y_test, pred))

    res_df = pd.DataFrame(results, columns=["Model", "Accuracy"]).sort_values(
        "Accuracy", ascending=False
    )
    print("\nüìä So s√°nh Accuracy:")
    print(res_df)

    # ===== 9. Confusion Matrix model t·ªët nh·∫•t =====
    best_model_name = res_df.iloc[0]["Model"]
    best_model = models[best_model_name]
    y_pred_best = best_model.predict(X_test)

    plt.figure(figsize=(6, 5))
    cm = confusion_matrix(y_test, y_pred_best, labels=best_model.classes_)
    sns.heatmap(
        cm,
        annot=True,
        fmt="d",
        cmap="Blues",
        xticklabels=best_model.classes_,
        yticklabels=best_model.classes_,
    )
    plt.title(f"Confusion Matrix ‚Äì {best_model_name}")
    plt.xlabel("Predicted")
    plt.ylabel("Actual")
    plt.tight_layout()
    plt.show()

    # ===== 10. PCA 2D demo =====
    SAMPLE_FOR_PCA = min(3000, X_tfidf.shape[0])
    idx_sample = np.random.RandomState(RANDOM_STATE).choice(
        X_tfidf.shape[0], SAMPLE_FOR_PCA, replace=False
    )
    X_sample = X_tfidf[idx_sample].toarray()
    y_sample = y.iloc[idx_sample].values

    pca = PCA(n_components=2, random_state=RANDOM_STATE)
    X_2d = pca.fit_transform(X_sample)

    plt.figure(figsize=(8, 6))
    sns.scatterplot(
        x=X_2d[:, 0], y=X_2d[:, 1], hue=y_sample, alpha=0.5, s=25, palette="Set2"
    )
    plt.title("Bi·ªÉu di·ªÖn PCA 2D c·ªßa tweet theo sentiment")
    plt.xlabel("PC1")
    plt.ylabel("PC2")
    plt.legend(title="Sentiment", bbox_to_anchor=(1.02, 1), loc="upper left")
    plt.tight_layout()
    plt.show()

    # ===== 11. D·ª± ƒëo√°n th·ª≠ tweet m·ªõi =====
    sample_tweets = [
        "The flight was delayed for 3 hours, terrible experience.",
        "Amazing service! The crew was so kind and helpful.",
        "It was okay, nothing special.",
        "Customer service solved my issue quickly, thanks!",
    ]

    tfidf_full = TfidfVectorizer(max_features=5000, stop_words="english")
    X_full = tfidf_full.fit_transform(X_text)
    best_model.fit(X_full, y)

    sample_vec = tfidf_full.transform(sample_tweets)
    sample_pred = best_model.predict(sample_vec)
    print("\nD·ª± ƒëo√°n v√≠ d·ª•:")
    for t, p in zip(sample_tweets, sample_pred):
        print(f"- {t}  ‚Üí  {p}")

    # ===== 12. Summary ƒë·ªÉ copy v√†o b√°o c√°o =====
    summary = {
        "Best Model": best_model_name,
        "Best Accuracy": float(res_df.iloc[0]["Accuracy"]),
        "Negative Ratio": float((df["airline_sentiment"] == "negative").mean()),
        "Mean Tweet Length": float(df["text_length"].mean()),
    }
    print("\n===== SUMMARY (copy v√†o b√°o c√°o) =====")
    for k, v in summary.items():
        print(f"{k}: {v}")
    print(
        "G·ª£i √Ω insight: Negative chi·∫øm t·ª∑ l·ªá l·ªõn; l√Ω do top th∆∞·ªùng l√† 'Late Flight', "
        "'Customer Service Issue'; h√£ng c√≥ t·ª∑ l·ªá negative cao; tweet negative th∆∞·ªùng d√†i h∆°n."
    )


if __name__ == "__main__":
    main()
